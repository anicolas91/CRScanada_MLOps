{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting CRS scores\n",
    "We now generate a pipeline that given a specific date, will forecast an estimated CRS cutoff value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pickle\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from utils import splitting as splt\n",
    "from utils import preprocessing as prep\n",
    "from utils import registering as regs\n",
    "\n",
    "# setup MLflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query_date(query_date):\n",
    "    ''' \n",
    "    This function converts the query date into a df alongside the X vals that are usually calculated during training\n",
    "    '''\n",
    "    url = 'https://www.canada.ca/content/dam/ircc/documents/json/ee_rounds_123_en.json'\n",
    "    df = prep.create_df_from_website(url)\n",
    "    df = prep.cleanup_df_general_rounds(df)\n",
    "\n",
    "    # retrieve all the data prior to the query date\n",
    "    df_sub = df.loc[df.index <= query_date].copy()\n",
    "\n",
    "    # create a new row just for prediction\n",
    "    df_query = df[:0].copy()\n",
    "    df_query.loc[query_date,'round type'] = 'General'\n",
    "    df_query.loc[query_date,'invitations issued'] = 0 #dummy data\n",
    "    df_query.loc[query_date,'CRS cutoff'] = 0 #dummy data \n",
    "\n",
    "    # concatenate to older data\n",
    "    df = pd.concat([df_query, df_sub])\n",
    "\n",
    "    # Calculate independent vars\n",
    "    df = prep.calculate_independent_vars(df)\n",
    "\n",
    "    #retain only top query\n",
    "    return df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prod_info_from_registry(reg_model_name= \"CRS_Model\"):\n",
    "    # get registered model\n",
    "    client = MlflowClient()\n",
    "    mymodel = client.get_registered_model(name= reg_model_name)\n",
    "\n",
    "    # get run Id of the production model in the register\n",
    "    for lv in mymodel.latest_versions:\n",
    "        stage = lv.current_stage\n",
    "        if stage == 'Production':\n",
    "            run_id = lv.run_id\n",
    "\n",
    "    # Get the details of the run\n",
    "    run_info = client.get_run(run_id)\n",
    "\n",
    "    # Retrieve the x_label from parameters\n",
    "    params = run_info.data.params\n",
    "    x_labels = ast.literal_eval(params['x_labels'])\n",
    "\n",
    "    # retrieve the label from the tags\n",
    "    tags = run_info.data.tags\n",
    "    model_type = tags['model_type']\n",
    "\n",
    "    model = regs.load_model_from_mlflow(run_id=run_id,model_type=model_type)\n",
    "\n",
    "    return model, x_labels, model_type, run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_run(query_date):\n",
    "    ''' \n",
    "    this is the main function to run during a prediction\n",
    "    '''\n",
    "    # establish the query date (to be replaced by a json input later)\n",
    "    #query_date = '31-Jul-2024'\n",
    "    # calculate all the usual x_labels\n",
    "    df_query = preprocess_query_date(query_date)\n",
    "    # get model and the labels used to calculate it\n",
    "    model, x_labels, _, _ = get_prod_info_from_registry(reg_model_name= \"CRS_Model\")\n",
    "    # get only x labels at the queried time\n",
    "    X_vals = df_query[x_labels]\n",
    "    #predict the CRS cutoff\n",
    "    y_pred = model.predict(X_vals)[0][0]\n",
    "\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for date 31-Jul-2024 the predicted crs score is 535\n"
     ]
    }
   ],
   "source": [
    "# run the main script see what happens\n",
    "query_date = '31-Jul-2024'\n",
    "y_pred =main_run(query_date)\n",
    "print(f'for date {query_date} the predicted crs score is {y_pred:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish\n",
    "This notebook can now be exported as a python script via: \n",
    "```bash\n",
    "jupyter nbconvert --to script predict.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating the final results df\n",
    "# df_result = pd.DataFrame()\n",
    "# df_result['date'] = [query_date]\n",
    "# df_result['round type'] = ['General']\n",
    "# df_result['CRS cutoff predicted'] = [y_pred]\n",
    "# df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # saving as parquet fil\n",
    "# output_file=f'./outputs/predicted_CRS_{query_date}.parquet'\n",
    "# # create any directories if does not exist\n",
    "# os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# df_result.to_parquet(\n",
    "#     output_file,\n",
    "#     engine='pyarrow',\n",
    "#     compression=None,\n",
    "#     index=False\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
